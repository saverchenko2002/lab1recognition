{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e4d962c-fd94-4042-a0be-0c87598c9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "SAMPLES_PER_SEC = 44100\n",
    "import tensorflow_io as tfio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2449125a-8e03-4169-92f6-059ce9f70757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(file_path):\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    pcm = tfio.audio.decode_mp3(audio_binary)\n",
    "\n",
    "    print('audio shape')\n",
    "    print(audio.shape)\n",
    "    spectrogram = tf.signal.stft(tf.transpose(audio), frame_length=256, frame_step=128)\n",
    "    \n",
    "    # spectrogram = tf.abs(spectrogram)\n",
    "    # print(spectrogram.shape)\n",
    "    # spectrogram = tf.expand_dims(spectrogram, axis=-1)\n",
    "    # print(spectrogram.shape)\n",
    "    # spectrogram = tf.squeeze(spectrogram, axis=[0,2])\n",
    "    print(spectrogram.shape)\n",
    "\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75ecc7bf-9bcc-4b14-abb0-7b95acf6e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"initial phrases voiced\"\n",
    "test_data_path = \"cross phrases voiced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08a91829-1376-4b09-a757-f1b6c2777966",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8511edf-94c0-43df-997b-9113353ff8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "unable to open file: libtensorflow_io.so, from paths: ['c:\\\\users\\\\sergeysaber\\\\pyver\\\\py392\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\ncaused by: ['c:\\\\users\\\\sergeysaber\\\\pyver\\\\py392\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0934123a47b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfile_path_to_display\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mspectrogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_spectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.wav'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-084812687adb>\u001b[0m in \u001b[0;36mcreate_spectrogram\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_spectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0maudio_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_mp3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_binary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'audio shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\u001b[0m in \u001b[0;36mdecode_mp3\u001b[1;34m(input, shape, name)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_audio_decode_mp3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attrb)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_library\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\u001b[0m in \u001b[0;36m_load_library\u001b[1;34m(filename, lib)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0merrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;34m\"unable to open file: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;33m+\u001b[0m \u001b[1;34mf\"{filename}, from paths: {filenames}\\ncaused by: {errs}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: unable to open file: libtensorflow_io.so, from paths: ['c:\\\\users\\\\sergeysaber\\\\pyver\\\\py392\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\ncaused by: ['c:\\\\users\\\\sergeysaber\\\\pyver\\\\py392\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(train_data_path):\n",
    "    file_path = os.path.join(train_data_path, filename)\n",
    "    \n",
    "    file_path_to_display = file_path\n",
    "\n",
    "    spectrogram = create_spectrogram(file_path)\n",
    "    X_train.append(spectrogram)\n",
    "    y_train.append(filename.replace('.wav',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda440af-0bd7-4493-8c97-233d3aca2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_to_display = create_spectrogram(file_path_to_display)\n",
    "print(f\"Размерность spectrogram_to_display перед логарифмированием: {spectrogram_to_display.numpy().shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db2740-400a-4392-b2bf-0c28aa5fe23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebddeae-0146-46a7-8baa-4ec5d9ab1226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7c6ed6ae-69db-4eee-a89b-6c7c8edfa44b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype complex64 cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-66bcd1f8a53a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectrogram_to_display\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'viridis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Спектрограмма'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Время'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Частота'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m         data=None, **kwargs):\n\u001b[1;32m-> 2724\u001b[1;33m     __ret = gca().imshow(\n\u001b[0m\u001b[0;32m   2725\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2726\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5523\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    700\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    701\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 702\u001b[1;33m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[0;32m    703\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype complex64 cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAD8CAYAAABAQ2EOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOYUlEQVR4nO3df6jdd33H8dfbxk7QqrBkIE20haXTzAl1l67DPyzoRto/kj8c0kBxSjH/rOKmCBVFpf6lMgdC/RGZdAraRf+QC0b6h+sQxEhv6VZMSiVUZ1OFRu36T9Ha7b0/zlHubm9yv03P5yYnfTwgcL/nfO45b/hwk2e+53vPqe4OAABjvOhCDwAAcCkTWwAAA4ktAICBxBYAwEBiCwBgILEFADDQlrFVVV+qqser6odnub+q6jNVdaqqHqyqNy5+TACA5TTlzNZdSfaf4/4bk+yd/zmc5HPPfywAgEvDlrHV3d9N8qtzLDmY5Ms9czzJK6vqVYsaEABgme1YwGNcmeTRdcen57f9fOPCqjqc2dmvvPSlL/3z1772tQt4egCAse6///5fdPeu8/neRcTWZN19JMmRJFlZWem1tbXtfHoAgPNSVf91vt+7iN9GfCzJnnXHu+e3AQC84C0itlaTvGP+W4nXJ3myu5/1EiIAwAvRli8jVtXXktyQZGdVnU7y0SQvTpLu/nySY0luSnIqyVNJ3jVqWACAZbNlbHX3oS3u7yR/t7CJAAAuId5BHgBgILEFADCQ2AIAGEhsAQAMJLYAAAYSWwAAA4ktAICBxBYAwEBiCwBgILEFADCQ2AIAGEhsAQAMJLYAAAYSWwAAA4ktAICBxBYAwEBiCwBgILEFADCQ2AIAGEhsAQAMJLYAAAYSWwAAA4ktAICBxBYAwEBiCwBgILEFADCQ2AIAGEhsAQAMJLYAAAYSWwAAA4ktAICBxBYAwEBiCwBgILEFADCQ2AIAGGhSbFXV/qp6uKpOVdXtm9z/6qq6t6oeqKoHq+qmxY8KALB8toytqrosyZ1JbkyyL8mhqtq3YdmHkxzt7muT3Jzks4seFABgGU05s3VdklPd/Uh3P53k7iQHN6zpJC+ff/2KJD9b3IgAAMtrSmxdmeTRdcen57et97Ekt1TV6STHkrxnsweqqsNVtVZVa2fOnDmPcQEAlsuiLpA/lOSu7t6d5KYkX6mqZz12dx/p7pXuXtm1a9eCnhoA4OI1JbYeS7Jn3fHu+W3r3ZrkaJJ09/eTvCTJzkUMCACwzKbE1n1J9lbV1VV1eWYXwK9uWPPTJG9Jkqp6XWax5XVCAOAFb8vY6u5nktyW5J4kD2X2W4cnquqOqjowX/b+JO+uqv9M8rUk7+zuHjU0AMCy2DFlUXcfy+zC9/W3fWTd1yeTvGmxowEALD/vIA8AMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYaFJsVdX+qnq4qk5V1e1nWfP2qjpZVSeq6quLHRMAYDnt2GpBVV2W5M4kf5XkdJL7qmq1u0+uW7M3yQeTvKm7n6iqPxo1MADAMplyZuu6JKe6+5HufjrJ3UkObljz7iR3dvcTSdLdjy92TACA5TQltq5M8ui649Pz29a7Jsk1VfW9qjpeVfs3e6CqOlxVa1W1dubMmfObGABgiSzqAvkdSfYmuSHJoSRfrKpXblzU3Ue6e6W7V3bt2rWgpwYAuHhNia3HkuxZd7x7ftt6p5Osdvdvu/vHSX6UWXwBALygTYmt+5Lsraqrq+ryJDcnWd2w5puZndVKVe3M7GXFRxY3JgDActoytrr7mSS3JbknyUNJjnb3iaq6o6oOzJfdk+SXVXUyyb1JPtDdvxw1NADAsqjuviBPvLKy0mtraxfkuQEAnouqur+7V87ne72DPADAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMNCk2Kqq/VX1cFWdqqrbz7HubVXVVbWyuBEBAJbXlrFVVZcluTPJjUn2JTlUVfs2WXdFkvcm+cGihwQAWFZTzmxdl+RUdz/S3U8nuTvJwU3WfTzJJ5L8eoHzAQAstSmxdWWSR9cdn57f9ntV9cYke7r7W+d6oKo6XFVrVbV25syZ5zwsAMCyed4XyFfVi5J8Osn7t1rb3Ue6e6W7V3bt2vV8nxoA4KI3JbYeS7Jn3fHu+W2/c0WS1yf596r6SZLrk6y6SB4AYFps3Zdkb1VdXVWXJ7k5yerv7uzuJ7t7Z3df1d1XJTme5EB3rw2ZGABgiWwZW939TJLbktyT5KEkR7v7RFXdUVUHRg8IALDMdkxZ1N3HkhzbcNtHzrL2huc/FgDApcE7yAMADCS2AAAGElsAAAOJLQCAgcQWAMBAYgsAYCCxBQAwkNgCABhIbAEADCS2AAAGElsAAAOJLQCAgcQWAMBAYgsAYCCxBQAwkNgCABhIbAEADCS2AAAGElsAAAOJLQCAgcQWAMBAYgsAYCCxBQAwkNgCABhIbAEADCS2AAAGElsAAAOJLQCAgcQWAMBAYgsAYCCxBQAwkNgCABhIbAEADCS2AAAGmhRbVbW/qh6uqlNVdfsm97+vqk5W1YNV9Z2qes3iRwUAWD5bxlZVXZbkziQ3JtmX5FBV7duw7IEkK939hiTfSPLJRQ8KALCMppzZui7Jqe5+pLufTnJ3koPrF3T3vd391PzweJLdix0TAGA5TYmtK5M8uu749Py2s7k1ybc3u6OqDlfVWlWtnTlzZvqUAABLaqEXyFfVLUlWknxqs/u7+0h3r3T3yq5duxb51AAAF6UdE9Y8lmTPuuPd89v+n6p6a5IPJXlzd/9mMeMBACy3KWe27kuyt6qurqrLk9ycZHX9gqq6NskXkhzo7scXPyYAwHLaMra6+5kktyW5J8lDSY5294mquqOqDsyXfSrJy5J8var+o6pWz/JwAAAvKFNeRkx3H0tybMNtH1n39VsXPBcAwCXBO8gDAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMJDYAgAYSGwBAAwktgAABhJbAAADTYqtqtpfVQ9X1amqun2T+/+gqv51fv8PquqqhU8KALCEtoytqrosyZ1JbkyyL8mhqtq3YdmtSZ7o7j9O8k9JPrHoQQEAltGUM1vXJTnV3Y9099NJ7k5ycMOag0n+Zf71N5K8papqcWMCACynHRPWXJnk0XXHp5P8xdnWdPczVfVkkj9M8ov1i6rqcJLD88PfVNUPz2doLgo7s2F/WRr2brnZv+Vl75bbn5zvN06JrYXp7iNJjiRJVa1198p2Pj+LY/+Wl71bbvZvedm75VZVa+f7vVNeRnwsyZ51x7vnt226pqp2JHlFkl+e71AAAJeKKbF1X5K9VXV1VV2e5OYkqxvWrCb52/nXf5Pk37q7FzcmAMBy2vJlxPk1WLcluSfJZUm+1N0nquqOJGvdvZrkn5N8papOJflVZkG2lSPPY24uPPu3vOzdcrN/y8veLbfz3r9yAgoAYBzvIA8AMJDYAgAYaHhs+aif5TVh795XVSer6sGq+k5VveZCzMnmttq/deveVlVdVX4l/SIyZf+q6u3zn8ETVfXV7Z6RzU34u/PVVXVvVT0w//vzpgsxJ89WVV+qqsfP9j6gNfOZ+d4+WFVvnPK4Q2PLR/0sr4l790CSle5+Q2afHPDJ7Z2Ss5m4f6mqK5K8N8kPtndCzmXK/lXV3iQfTPKm7v7TJH+/3XPybBN/9j6c5Gh3X5vZL5R9dnun5BzuSrL/HPffmGTv/M/hJJ+b8qCjz2z5qJ/lteXedfe93f3U/PB4Zu/BxsVhys9eknw8s//g/Ho7h2NLU/bv3Unu7O4nkqS7H9/mGdnclL3rJC+ff/2KJD/bxvk4h+7+bmbvqnA2B5N8uWeOJ3llVb1qq8cdHVubfdTPlWdb093PJPndR/1wYU3Zu/VuTfLtoRPxXGy5f/PT33u6+1vbORiTTPn5uybJNVX1vao6XlXn+t8422fK3n0syS1VdTrJsSTv2Z7RWIDn+m9jkm3+uB4uTVV1S5KVJG++0LMwTVW9KMmnk7zzAo/C+duR2UsZN2R2Vvm7VfVn3f3fF3IoJjmU5K7u/seq+svM3qfy9d39vxd6MMYYfWbLR/0sryl7l6p6a5IPJTnQ3b/ZptnY2lb7d0WS1yf596r6SZLrk6y6SP6iMeXn73SS1e7+bXf/OMmPMosvLqwpe3drkqNJ0t3fT/KSzD6kmovfpH8bNxodWz7qZ3ltuXdVdW2SL2QWWq4Xubicc/+6+8nu3tndV3X3VZldc3egu8/7g1ZZqCl/d34zs7Naqaqdmb2s+Mg2zsjmpuzdT5O8JUmq6nWZxdaZbZ2S87Wa5B3z30q8PsmT3f3zrb5p6MuIAz/qh8Em7t2nkrwsydfnv9Pw0+4+cMGG5vcm7h8XqYn7d0+Sv66qk0n+J8kHuturAhfYxL17f5IvVtU/ZHax/DudZLg4VNXXMvtPzM75NXUfTfLiJOnuz2d2jd1NSU4leSrJuyY9rv0FABjHO8gDAAwktgAABhJbAAADiS0AgIHEFgDAQGILAGAgsQUAMND/ATykpOaMw5isAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(np.log1p(spectrogram_to_display.numpy()), aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.title('Спектрограмма')\n",
    "plt.xlabel('Время')\n",
    "plt.ylabel('Частота')\n",
    "plt.colorbar(format='%+2.0f дБ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e343f6f6-e8a2-4143-8a0a-cc9ec825a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_phrases_txt_path = 'initial_phrases.txt'\n",
    "initial_phrases_mp3_folder_path = 'initial phrases voiced/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5156a2a5-596b-412f-af4c-34427070d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_phrases_df = pd.DataFrame(columns=range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de244fd-0d98-4b29-a72d-0ec715970056",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_phrases_df.columns = [\"file_name\", \"transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd04448-c84a-4011-afe8-c3f5a076b7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name, transcription]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_phrases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0936e8d-4f91-420f-8085-84dfdda9fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(initial_phrases_txt_path, 'r', encoding='utf-8') as file:\n",
    "    initial_phrases_text = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc097e9f-d89e-46a1-83ff-ac4df32bc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_phrases_files_path = [initial_phrases_mp3_folder_path + phrase + '.wav' for phrase in initial_phrases_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed897da-96b9-497c-8125-48611039af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_phrases_df['transcription'] = initial_phrases_text\n",
    "initial_phrases_df['file_name'] = initial_phrases_files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9669e4-8956-460d-97a3-f30af3bdd816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     file_name    transcription\n",
      "0     initial phrases voiced/Красивая роза.wav    Красивая роза\n",
      "1    initial phrases voiced/Свежая морковь.wav   Свежая морковь\n",
      "2      initial phrases voiced/Яркая звезда.wav     Яркая звезда\n",
      "3      initial phrases voiced/Нежная лилия.wav     Нежная лилия\n",
      "4      initial phrases voiced/Теплая кофта.wav     Теплая кофта\n",
      "5    initial phrases voiced/Мягкая подушка.wav   Мягкая подушка\n",
      "6       initial phrases voiced/Чистая река.wav      Чистая река\n",
      "7    initial phrases voiced/Быстрая лошадь.wav   Быстрая лошадь\n",
      "8     initial phrases voiced/Зеленая трава.wav    Зеленая трава\n",
      "9    initial phrases voiced/Спокойная река.wav   Спокойная река\n",
      "10    initial phrases voiced/Крепкая чашка.wav    Крепкая чашка\n",
      "11     initial phrases voiced/Высокая гора.wav     Высокая гора\n",
      "12  initial phrases voiced/Уютная квартира.wav  Уютная квартира\n",
      "13  initial phrases voiced/Светлая комната.wav  Светлая комната\n",
      "14  initial phrases voiced/Прозрачная вода.wav  Прозрачная вода\n",
      "15  initial phrases voiced/Круглая тарелка.wav  Круглая тарелка\n",
      "16      initial phrases voiced/Густая роща.wav      Густая роща\n",
      "17      initial phrases voiced/Новая книга.wav      Новая книга\n",
      "18    initial phrases voiced/Сильная волна.wav    Сильная волна\n",
      "19       initial phrases voiced/Тихая ночь.wav       Тихая ночь\n"
     ]
    }
   ],
   "source": [
    "print(initial_phrases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e72a79f-19a5-4aa9-9806-e345a876e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An integer scalar Tensor. The window length in samples.\n",
    "frame_length = 256\n",
    "# An integer scalar Tensor. The number of samples to step.\n",
    "frame_step = 160\n",
    "# An integer scalar Tensor. The size of the FFT to apply.\n",
    "# If not provided, uses the smallest power of 2 enclosing frame_length.\n",
    "fft_length = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72211b9a-22e2-4eff-b558-fb81cf7930bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_single_sample(mp3_file_path, label):\n",
    "    ###########################################\n",
    "    ##  Process the Audio\n",
    "    ##########################################\n",
    "    # 1. Read mp3 file\n",
    "    file = tf.io.read_file(mp3_file_path)\n",
    "    # 2. Decode the mp3 file\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    # 3. Change type to float\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    # 4. Get the spectrogram\n",
    "    spectrogram = tf.signal.stft(\n",
    "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
    "    )\n",
    "    # 5. We only need the magnitude, which can be derived by applying tf.abs\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "    # 6. normalisation\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "    ###########################################\n",
    "    ##  Process the label\n",
    "    ##########################################\n",
    "    # 7. Convert label to Lower case\n",
    "    label = tf.strings.lower(label)\n",
    "    # 8. Split the label\n",
    "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
    "    # 9. Map the characters in label to numbers\n",
    "    print(label)\n",
    "    # label = char_to_num(label)\n",
    "    # 10. Return a dict as our model is expecting two inputs\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bae2804-a020-4d85-8bc8-dbdf611d7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(initial_phrases_df[\"file_name\"]), list(initial_phrases_df[\"transcription\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "033bed92-2929-485e-9f66-77712ad2a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9a\\xd1\\x80\\xd0\\xb0\\xd1\\x81\\xd0\\xb8\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9a\\xd1\\x80\\xd0\\xb0\\xd1\\x81\\xd0\\xb8\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd0\\xb6\\xd0\\xb0\\xd1\\x8f \\xd0\\xbc\\xd0\\xbe\\xd1\\x80\\xd0\\xba\\xd0\\xbe\\xd0\\xb2\\xd1\\x8c.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd0\\xb6\\xd0\\xb0\\xd1\\x8f \\xd0\\xbc\\xd0\\xbe\\xd1\\x80\\xd0\\xba\\xd0\\xbe\\xd0\\xb2\\xd1\\x8c'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xaf\\xd1\\x80\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb7\\xd0\\xb2\\xd0\\xb5\\xd0\\xb7\\xd0\\xb4\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xaf\\xd1\\x80\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb7\\xd0\\xb2\\xd0\\xb5\\xd0\\xb7\\xd0\\xb4\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9d\\xd0\\xb5\\xd0\\xb6\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xb8\\xd0\\xbb\\xd0\\xb8\\xd1\\x8f.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9d\\xd0\\xb5\\xd0\\xb6\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xb8\\xd0\\xbb\\xd0\\xb8\\xd1\\x8f'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa2\\xd0\\xb5\\xd0\\xbf\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd1\\x84\\xd1\\x82\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa2\\xd0\\xb5\\xd0\\xbf\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd1\\x84\\xd1\\x82\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9c\\xd1\\x8f\\xd0\\xb3\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xbf\\xd0\\xbe\\xd0\\xb4\\xd1\\x83\\xd1\\x88\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9c\\xd1\\x8f\\xd0\\xb3\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xbf\\xd0\\xbe\\xd0\\xb4\\xd1\\x83\\xd1\\x88\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa7\\xd0\\xb8\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa7\\xd0\\xb8\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x91\\xd1\\x8b\\xd1\\x81\\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xbe\\xd1\\x88\\xd0\\xb0\\xd0\\xb4\\xd1\\x8c.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x91\\xd1\\x8b\\xd1\\x81\\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xbe\\xd1\\x88\\xd0\\xb0\\xd0\\xb4\\xd1\\x8c'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x97\\xd0\\xb5\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd0\\xb2\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x97\\xd0\\xb5\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd0\\xb2\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xbf\\xd0\\xbe\\xd0\\xba\\xd0\\xbe\\xd0\\xb9\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xbf\\xd0\\xbe\\xd0\\xba\\xd0\\xbe\\xd0\\xb9\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9a\\xd1\\x80\\xd0\\xb5\\xd0\\xbf\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd1\\x87\\xd0\\xb0\\xd1\\x88\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9a\\xd1\\x80\\xd0\\xb5\\xd0\\xbf\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd1\\x87\\xd0\\xb0\\xd1\\x88\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x92\\xd1\\x8b\\xd1\\x81\\xd0\\xbe\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb3\\xd0\\xbe\\xd1\\x80\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x92\\xd1\\x8b\\xd1\\x81\\xd0\\xbe\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb3\\xd0\\xbe\\xd1\\x80\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa3\\xd1\\x8e\\xd1\\x82\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xb2\\xd0\\xb0\\xd1\\x80\\xd1\\x82\\xd0\\xb8\\xd1\\x80\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa3\\xd1\\x8e\\xd1\\x82\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xb2\\xd0\\xb0\\xd1\\x80\\xd1\\x82\\xd0\\xb8\\xd1\\x80\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd1\\x82\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd0\\xbc\\xd0\\xbd\\xd0\\xb0\\xd1\\x82\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd1\\x82\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd0\\xbc\\xd0\\xbd\\xd0\\xb0\\xd1\\x82\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd1\\x80\\xd0\\xb0\\xd1\\x87\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xb4\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd1\\x80\\xd0\\xb0\\xd1\\x87\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xb4\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9a\\xd1\\x80\\xd1\\x83\\xd0\\xb3\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd0\\xb0\\xd1\\x80\\xd0\\xb5\\xd0\\xbb\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9a\\xd1\\x80\\xd1\\x83\\xd0\\xb3\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd0\\xb0\\xd1\\x80\\xd0\\xb5\\xd0\\xbb\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x93\\xd1\\x83\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd1\\x89\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x93\\xd1\\x83\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd1\\x89\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9d\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbd\\xd0\\xb8\\xd0\\xb3\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9d\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbd\\xd0\\xb8\\xd0\\xb3\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xb8\\xd0\\xbb\\xd1\\x8c\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xbb\\xd0\\xbd\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xb8\\xd0\\xbb\\xd1\\x8c\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xbb\\xd0\\xbd\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa2\\xd0\\xb8\\xd1\\x85\\xd0\\xb0\\xd1\\x8f \\xd0\\xbd\\xd0\\xbe\\xd1\\x87\\xd1\\x8c.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa2\\xd0\\xb8\\xd1\\x85\\xd0\\xb0\\xd1\\x8f \\xd0\\xbd\\xd0\\xbe\\xd1\\x87\\xd1\\x8c'>)\n"
     ]
    }
   ],
   "source": [
    "for ele in train_dataset: \n",
    "    print(ele) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b5e81f-a390-4cd2-9b3a-461deedffb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"UnicodeSplit/UnicodeEncode/UnicodeEncode/UnicodeEncode:0\", shape=(None,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d3a33e9-1dcb-4787-96f4-a5b78840199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9a\\xd1\\x80\\xd0\\xb0\\xd1\\x81\\xd0\\xb8\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9a\\xd1\\x80\\xd0\\xb0\\xd1\\x81\\xd0\\xb8\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd0\\xb6\\xd0\\xb0\\xd1\\x8f \\xd0\\xbc\\xd0\\xbe\\xd1\\x80\\xd0\\xba\\xd0\\xbe\\xd0\\xb2\\xd1\\x8c.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd0\\xb6\\xd0\\xb0\\xd1\\x8f \\xd0\\xbc\\xd0\\xbe\\xd1\\x80\\xd0\\xba\\xd0\\xbe\\xd0\\xb2\\xd1\\x8c'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xaf\\xd1\\x80\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb7\\xd0\\xb2\\xd0\\xb5\\xd0\\xb7\\xd0\\xb4\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xaf\\xd1\\x80\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb7\\xd0\\xb2\\xd0\\xb5\\xd0\\xb7\\xd0\\xb4\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9d\\xd0\\xb5\\xd0\\xb6\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xb8\\xd0\\xbb\\xd0\\xb8\\xd1\\x8f.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9d\\xd0\\xb5\\xd0\\xb6\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xb8\\xd0\\xbb\\xd0\\xb8\\xd1\\x8f'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa2\\xd0\\xb5\\xd0\\xbf\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd1\\x84\\xd1\\x82\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa2\\xd0\\xb5\\xd0\\xbf\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd1\\x84\\xd1\\x82\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9c\\xd1\\x8f\\xd0\\xb3\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xbf\\xd0\\xbe\\xd0\\xb4\\xd1\\x83\\xd1\\x88\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9c\\xd1\\x8f\\xd0\\xb3\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xbf\\xd0\\xbe\\xd0\\xb4\\xd1\\x83\\xd1\\x88\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa7\\xd0\\xb8\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa7\\xd0\\xb8\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x91\\xd1\\x8b\\xd1\\x81\\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xbe\\xd1\\x88\\xd0\\xb0\\xd0\\xb4\\xd1\\x8c.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x91\\xd1\\x8b\\xd1\\x81\\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd1\\x8f \\xd0\\xbb\\xd0\\xbe\\xd1\\x88\\xd0\\xb0\\xd0\\xb4\\xd1\\x8c'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x97\\xd0\\xb5\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd0\\xb2\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x97\\xd0\\xb5\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd1\\x80\\xd0\\xb0\\xd0\\xb2\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xbf\\xd0\\xbe\\xd0\\xba\\xd0\\xbe\\xd0\\xb9\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xbf\\xd0\\xbe\\xd0\\xba\\xd0\\xbe\\xd0\\xb9\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xb5\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9a\\xd1\\x80\\xd0\\xb5\\xd0\\xbf\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd1\\x87\\xd0\\xb0\\xd1\\x88\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9a\\xd1\\x80\\xd0\\xb5\\xd0\\xbf\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd1\\x87\\xd0\\xb0\\xd1\\x88\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x92\\xd1\\x8b\\xd1\\x81\\xd0\\xbe\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb3\\xd0\\xbe\\xd1\\x80\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x92\\xd1\\x8b\\xd1\\x81\\xd0\\xbe\\xd0\\xba\\xd0\\xb0\\xd1\\x8f \\xd0\\xb3\\xd0\\xbe\\xd1\\x80\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa3\\xd1\\x8e\\xd1\\x82\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xb2\\xd0\\xb0\\xd1\\x80\\xd1\\x82\\xd0\\xb8\\xd1\\x80\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa3\\xd1\\x8e\\xd1\\x82\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xb2\\xd0\\xb0\\xd1\\x80\\xd1\\x82\\xd0\\xb8\\xd1\\x80\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd1\\x82\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd0\\xbc\\xd0\\xbd\\xd0\\xb0\\xd1\\x82\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xb2\\xd0\\xb5\\xd1\\x82\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbe\\xd0\\xbc\\xd0\\xbd\\xd0\\xb0\\xd1\\x82\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd1\\x80\\xd0\\xb0\\xd1\\x87\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xb4\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd0\\xb7\\xd1\\x80\\xd0\\xb0\\xd1\\x87\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xb4\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9a\\xd1\\x80\\xd1\\x83\\xd0\\xb3\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd0\\xb0\\xd1\\x80\\xd0\\xb5\\xd0\\xbb\\xd0\\xba\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9a\\xd1\\x80\\xd1\\x83\\xd0\\xb3\\xd0\\xbb\\xd0\\xb0\\xd1\\x8f \\xd1\\x82\\xd0\\xb0\\xd1\\x80\\xd0\\xb5\\xd0\\xbb\\xd0\\xba\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x93\\xd1\\x83\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd1\\x89\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x93\\xd1\\x83\\xd1\\x81\\xd1\\x82\\xd0\\xb0\\xd1\\x8f \\xd1\\x80\\xd0\\xbe\\xd1\\x89\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\x9d\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbd\\xd0\\xb8\\xd0\\xb3\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\x9d\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x8f \\xd0\\xba\\xd0\\xbd\\xd0\\xb8\\xd0\\xb3\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa1\\xd0\\xb8\\xd0\\xbb\\xd1\\x8c\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xbb\\xd0\\xbd\\xd0\\xb0.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa1\\xd0\\xb8\\xd0\\xbb\\xd1\\x8c\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xbe\\xd0\\xbb\\xd0\\xbd\\xd0\\xb0'>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'initial phrases voiced/\\xd0\\xa2\\xd0\\xb8\\xd1\\x85\\xd0\\xb0\\xd1\\x8f \\xd0\\xbd\\xd0\\xbe\\xd1\\x87\\xd1\\x8c.wav'>, <tf.Tensor: shape=(), dtype=string, numpy=b'\\xd0\\xa2\\xd0\\xb8\\xd1\\x85\\xd0\\xb0\\xd1\\x8f \\xd0\\xbd\\xd0\\xbe\\xd1\\x87\\xd1\\x8c'>)\n"
     ]
    }
   ],
   "source": [
    "for ele in train_dataset: \n",
    "    print(ele) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49adf22b-6f77-4bb7-a900-d8fefd052691",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[1], expected a dimension of 1, got 2\n\t [[{{node Squeeze}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8f3d52704635>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mspectrogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mspectrogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrim_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[1;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    750\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3015\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3016\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3017\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sergeysaber\\pyver\\py392\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7164\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[1], expected a dimension of 1, got 2\n\t [[{{node Squeeze}}]] [Op:IteratorGetNext]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "for batch in train_dataset.take(1):\n",
    "    spectrogram = batch[0][0].numpy()\n",
    "    spectrogram = np.array([np.trim_zeros(x) for x in np.transpose(spectrogram)])\n",
    "    label = batch[1][0]\n",
    "    # Spectrogram\n",
    "    label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    ax.imshow(spectrogram, vmax=1)\n",
    "    ax.set_title(label)\n",
    "    ax.axis(\"off\")\n",
    "    # Wav\n",
    "    file = tf.io.read_file(wavs_path + list(df_train[\"file_name\"])[0] + \".wav\")\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = audio.numpy()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    plt.plot(audio)\n",
    "    ax.set_title(\"Signal Wave\")\n",
    "    ax.set_xlim(0, len(audio))\n",
    "    display.display(display.Audio(np.transpose(audio), rate=16000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8ad82-0774-4806-9e9b-786ebc1aa9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
